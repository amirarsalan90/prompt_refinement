{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\"env_variables.env\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptrefiner import AbstractLLM, PromptTrackerClass, OpenaiCommunicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "class LlamaCPPModel(AbstractLLM):\n",
    "    def __init__(self, base_url, api_key, temperature=0.1, max_tokens=200):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        from openai import OpenAI\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        \n",
    "    def predict(self, input_text, system_prompt):\n",
    "        response = self.client.chat.completions.create(\n",
    "        model=\"mistral\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # Update this as per your needs\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ],\n",
    "        temperature=self.temperature,\n",
    "        max_tokens=self.max_tokens,\n",
    "    )\n",
    "        llm_response = response.choices[0].message.content\n",
    "        return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamamodel = LlamaCPPModel(base_url=\"http://localhost:8000/v1\", api_key=\"sk-xxx\", temperature=0.1, max_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "output_evaluation_1 = \"\"\"{\n",
    "    \"John\": {\"cousin\": \"Mark\", \"wife\": \"Lisa\"},\n",
    "    \"Lisa\": {\"husband\": \"John\", \"best friend\": \"Tina\"},\n",
    "    \"Mark\": {\"cousin\": \"John\", \"sister\": \"Tina\"},\n",
    "    \"Tina\": {\"best friend\": \"Lisa\", \"brother\": \"Mark\"}\n",
    "}\"\"\"\n",
    "\n",
    "output_evaluation_2 = \"\"\"{\n",
    "    \"Sarah\": {\"role\": \"manager\", \"assistant\": \"Tom\", \"meeting with\": [\"Tom\", \"Emily\", \"Alex\"]},\n",
    "    \"Tom\": {\"role\": \"assistant\", \"manager\": \"Sarah\", \"meeting with\": [\"Sarah\", \"Emily\", \"Alex\"]},\n",
    "    \"Emily\": {\"role\": \"project leader\", \"meeting with\": [\"Sarah\", \"Tom\", \"Alex\"], \"mentor\": \"Alex\"},\n",
    "    \"Alex\": {\"role\": \"CEO\", \"meeting with\": [\"Sarah\", \"Tom\", \"Emily\"], \"mentee\": \"Emily\"}\n",
    "}\"\"\"\n",
    "\n",
    "output_evaluation_3 = \"\"\"{\n",
    "    \"Kevin\": {\"neighbor\": \"Lucas\", \"son\": \"Mike\", \"played with\": \"Lucas\"},\n",
    "    \"Lucas\": {\"neighbor\": \"Kevin\", \"daughter\": \"Jenny\", \"played with\": \"Kevin\"},\n",
    "    \"Jenny\": {\"father\": \"Lucas\", \"business partner\": \"Mike\", \"cousin\": \"Tim\"},\n",
    "    \"Mike\": {\"father\": \"Kevin\", \"business partner\": \"Jenny\", \"friend\": \"Tim\"},\n",
    "    \"Tim\": {\"cousin\": \"Jenny\", \"friend\": \"Mike\"}\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_evaluations = [input_evaluation_1, input_evaluation_2, input_evaluation_3]\n",
    "output_evaluations = [output_evaluation_1, output_evaluation_2, output_evaluation_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "init_sys_prompt = \"\"\"You are an AI that receives an input text about relatiosnhips between people and returns their relatioships as a python dictionary\"\"\"\n",
    "promptTracker = PromptTrackerClass(init_system_prompt = init_sys_prompt)\n",
    "promptTracker.add_evaluation_examples(input_evaluations, output_evaluations)\n",
    "#promptTracker.add_evaluation_examples(input_evaluation_2, output_evaluation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker.run_initial_prompt(llm_model=llamamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promptTracker.llm_responses[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_communicator = OpenaiCommunicator(client=client, openai_model_code=\"gpt-4-0125-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_communicator.refine_system_prompt(prompttracker=promptTracker, llm_model=llamamodel, number_of_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promptTracker.llm_responses[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promptTracker.llm_system_prompts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refiner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
