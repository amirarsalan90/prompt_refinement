{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Type, Union\n",
    "from typing import List\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sglang as sgl\n",
    "from pydantic import BaseModel, conlist\n",
    "from typing import List\n",
    "from sglang.srt.constrained import build_regex_from_object\n",
    "\n",
    "load_dotenv(\"env_variable.env\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptsList(BaseModel):\n",
    "    #the list name has an important effect on the response! choose it wisely!\n",
    "    Concepts_List: conlist(str, max_length=10)\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def pydantic_gen_ex(s, list_element):\n",
    "    s += list_element\n",
    "    s += sgl.gen(\n",
    "        \"\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0,\n",
    "        regex=build_regex_from_object(ConceptsList),  # Requires pydantic >= 2.0\n",
    "    )\n",
    "\n",
    "sgl.set_default_backend(sgl.RuntimeEndpoint(\"http://localhost:30000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mistral_total_prompt(system_prompt, input):\n",
    "    final_input = f\"\"\"text:{input}\n",
    "Concepts_List:\"\"\"    \n",
    "    final_prompt = system_prompt + \"\\n\" + final_input\n",
    "\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_llm_call(input):\n",
    "    state = pydantic_gen_ex.run(input)\n",
    "    return str(json.loads(state.text()[len(input):])[\"Concepts_List\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PromptsClass:\n",
    "    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n",
    "    mistral_system_prompts: List[str]\n",
    "    mistral_responses: List[str]\n",
    "    target_input: str\n",
    "    target_list: List[str]\n",
    "\n",
    "    def clear_state(self):\n",
    "        self.mistral_system_prompts = []\n",
    "        self.mistral_responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_for_evaluation = \"She said: 'today was supposed to be a day of celebration and joy in Kansas, instead it is another day where America has experience senselense gun violence' in response to what happened in Kansas near coca-cola branch\"\n",
    "\n",
    "output_list_for_evaluation = [\"Gun violence\", \"Coca-cola\", \"Kansas city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker = PromptsClass([],[],\"\",[])\n",
    "promptTracker.target_input = input_text_for_evaluation\n",
    "promptTracker.target_list = output_list_for_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating initial mistral input output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sys_prompt = \"\"\"You are an AI designed to find a LIMITED list of GENERAL concepts associated with a given piece of text. The list size should NOT exceed 10. You Must use standardized words.\n",
    "\n",
    "###\n",
    "Here are some examples:\n",
    "\n",
    "\n",
    "Text: \"israel supporters attacks female palestine activist\"\n",
    "Concepts_List: [\"Hate speech\", \"Palestine\"]\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker.mistral_system_prompts.append(init_sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mistral_inputs = create_mistral_total_prompt(promptTracker.mistral_system_prompts[-1], promptTracker.target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_mistral = local_llm_call(initial_mistral_inputs)\n",
    "promptTracker.mistral_responses.append(output_from_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI GPT4 for refinement of system prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_sys_prompt = \"\"\"You are an AI assistant who is expert in creating promtps for LLMs. you job is to modify and enhance a prompt for a 7b mistral instruct model. The mistral is supposed to receive an input text, and return a list of strings, entities, brand names, etc in that input text. This LLM is going to be used for .... The prompt to the mistral model can include some examples that lead the model's behavior. Mistral model performs constrained decoding, meaning that it only generated a list of strings.\n",
    "\n",
    "A number of experiments have been done on different system prompts for mistral and the output. Those experiments which include tested system prompt, tested INPUT TO MISTRAL, and the resulting output from Mistral are provided to you. Your job is to observe the experiments, and come up with a better system prompt for Mistral to achieve the expected output. you can provide some examples, or remove some examples in your suggested system prompt. Remember that total number of examples should be limited, because it adds extra computation and we can't afford it. Note that the examples given in the system prompt of mistral should be enclosed by ### ###. Pay attention to the fact that, you are not allowed to use INPUT TO MISTRAL text in your examples for your suggested mistral system prompt.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openai_user_prompt(prompttracker):\n",
    "    total_prompt = \"\"\n",
    "\n",
    "    for i in range(len(prompttracker.mistral_responses)):\n",
    "        total_prompt += f\"\"\"\\n\\n\n",
    "Experiment {i}\n",
    "Mistral System Prompt:\n",
    "{prompttracker.mistral_system_prompts[i]}\n",
    "\n",
    "\n",
    "INPUT TO MISTRAL:\n",
    "{prompttracker.target_input}\n",
    "\n",
    "\n",
    "output from Mistral:\n",
    "{prompttracker.mistral_responses[i]}\n",
    "\n",
    "\n",
    "what was expected to be output from Mistral:\n",
    "{str(prompttracker.target_list)} \\n\\n\n",
    "\"\"\"\n",
    "    return total_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSystemPrompt(BaseModel):\n",
    "    #the list name has an important effect on the response! choose it wisely!\n",
    "    Enhanced_System_Prompt: str\n",
    "\n",
    "\n",
    "def request_to_openai(prompttracker):\n",
    "    openai_user_prompt = create_openai_user_prompt(prompttracker=prompttracker)\n",
    "    response = client.chat.completions.create(\n",
    "        temperature = 0.1,\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": openai_sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": openai_user_prompt},\n",
    "            ],\n",
    "        functions=[\n",
    "            {\n",
    "            \"name\": \"Enhanced_System_Prompt\",\n",
    "            \"description\": \"Enhanced System Prompt for Mistral LLM\",\n",
    "            \"parameters\": EnhancedSystemPrompt.model_json_schema()\n",
    "            }\n",
    "        ],\n",
    "        function_call={\"name\": \"Enhanced_System_Prompt\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.function_call.arguments)['Enhanced_System_Prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_system_prompt_with_gpt4(number_of_iterations):\n",
    "    for i in range(number_of_iterations):\n",
    "        openai_suggestion = request_to_openai(prompttracker=promptTracker)\n",
    "        promptTracker.mistral_system_prompts.append(openai_suggestion)\n",
    "        mistral_inputs = create_mistral_total_prompt(promptTracker.mistral_system_prompts[-1], promptTracker.target_input)\n",
    "        output_from_mistral = local_llm_call(mistral_inputs)\n",
    "        promptTracker.mistral_responses.append(output_from_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_system_prompt_with_gpt4(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI designed to find a LIMITED list of GENERAL concepts associated with a given piece of text. The list size should NOT exceed 10. You Must use standardized words.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "\n",
      "Text: \"israel supporters attacks female palestine activist\"\n",
      "Concepts_List: [\"Hate speech\", \"Palestine\"]\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(promptTracker.mistral_system_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI designed to extract a concise list of specific entities, brand names, and key concepts from a given piece of text. Your output should be a list of no more than 10 items, focusing on the most relevant and specific details mentioned in the text. Use standardized, recognizable terms for entities and concepts.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "Text: \"The new iPhone 12 was released yesterday, sparking excitement among Apple enthusiasts.\"\n",
      "Concepts_List: [\"iPhone 12\", \"Apple\"]\n",
      "\n",
      "Text: \"A devastating earthquake hit Tokyo last night, causing widespread damage.\"\n",
      "Concepts_List: [\"Earthquake\", \"Tokyo\"]\n",
      "\n",
      "Text: \"israel supporters attacks female palestine activist\"\n",
      "Concepts_List: [\"Hate speech\", \"Palestine\"]\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(promptTracker.mistral_system_prompts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI designed to extract a precise list of specific entities, brand names, and key concepts from a given piece of text. Your output should consist of a concise list of no more than 10 items, prioritizing the most relevant and specific details mentioned in the text. Use standardized, recognizable terms for entities and concepts. Ensure that brand names are clearly identified and included when mentioned.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "Text: \"The new iPhone 12 was released yesterday, sparking excitement among Apple enthusiasts.\"\n",
      "Concepts_List: [\"iPhone 12\", \"Apple\"]\n",
      "\n",
      "Text: \"A devastating earthquake hit Tokyo last night, causing widespread damage.\"\n",
      "Concepts_List: [\"Earthquake\", \"Tokyo\"]\n",
      "\n",
      "Text: \"Protesters in Paris demand action on climate change.\"\n",
      "Concepts_List: [\"Climate change\", \"Paris\"]\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(promptTracker.mistral_system_prompts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gun violence', 'Coca-cola', 'Kansas city']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTracker.target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gun violence', 'Celebration', 'Joy', 'America', 'Kansas']\n",
      "['Kansas', 'America', 'Gun violence']\n",
      "['Kansas', 'America', 'gun violence', 'Coca-Cola']\n"
     ]
    }
   ],
   "source": [
    "for i in promptTracker.mistral_responses:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
