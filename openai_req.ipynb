{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Type, Union\n",
    "from typing import List\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sglang as sgl\n",
    "from pydantic import BaseModel, conlist\n",
    "from typing import List\n",
    "from sglang.srt.constrained import build_regex_from_object\n",
    "\n",
    "import ast\n",
    "\n",
    "load_dotenv(\"env_variable.env\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptsList(BaseModel):\n",
    "    #the list name has an important effect on the response! choose it wisely!\n",
    "    Concepts_List: conlist(str, max_length=10)\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def pydantic_gen_ex(s, list_element):\n",
    "    s += list_element\n",
    "    s += sgl.gen(\n",
    "        \"\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0,\n",
    "        regex=build_regex_from_object(ConceptsList),  # Requires pydantic >= 2.0\n",
    "    )\n",
    "\n",
    "sgl.set_default_backend(sgl.RuntimeEndpoint(\"http://localhost:30000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mistral_total_prompt(system_prompt, input):\n",
    "    final_input = f\"\"\"text:{input}\n",
    "Concepts_List:\"\"\"    \n",
    "    final_prompt = system_prompt + \"\\n\" + final_input\n",
    "\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_llm_call(input):\n",
    "    state = pydantic_gen_ex.run(input)\n",
    "    return str(json.loads(state.text()[len(input):])[\"Concepts_List\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PromptsClass:\n",
    "    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n",
    "    mistral_system_prompts: List[str]\n",
    "    target_input: List[str]\n",
    "    target_output: List[str]\n",
    "    mistral_responses: List[List[str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_evaluation_1 = \"She said: 'today was supposed to be a day of celebration and joy in Kansas, instead it is another day where America has experience senselense gun violence' in response to what happened in Kansas near coca-cola branch\"\n",
    "\n",
    "output_evaluation_1 = [\"Gun violence\", \"Coca-cola\", \"Kansas city\"]\n",
    "\n",
    "input_evaluation_2 = \"I would say the best place to go for your honeymoon is Paris, but some say it's overrated\"\n",
    "\n",
    "output_evaluation_2 = [\"Paris\", \"Honeymoon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker = PromptsClass([],[],[],[])\n",
    "promptTracker.target_input.append(input_evaluation_1)\n",
    "promptTracker.target_input.append(input_evaluation_2)\n",
    "promptTracker.target_output.append(str(output_evaluation_1))\n",
    "promptTracker.target_output.append(str(output_evaluation_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Gun violence', 'Coca-cola', 'Kansas city']\", \"['Paris', 'Honeymoon']\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTracker.target_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"She said: 'today was supposed to be a day of celebration and joy in Kansas, instead it is another day where America has experience senselense gun violence' in response to what happened in Kansas near coca-cola branch\",\n",
       " \"I would say the best place to go for your honeymoon is Paris, but some say it's overrated\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTracker.target_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating initial mistral input output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sys_prompt = \"\"\"You are an AI designed to find a LIMITED list of GENERAL concepts associated with a given piece of text. The list size should NOT exceed 10. You Must use standardized words.\n",
    "\n",
    "###\n",
    "Here are some examples:\n",
    "\n",
    "\n",
    "Text: \"israel supporters attacks female palestine activist\"\n",
    "Concepts_List: [\"Hate speech\", \"Palestine\"]\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker.mistral_system_prompts.append(init_sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTracker.mistral_responses.append([])\n",
    "for i in range(len(promptTracker.target_input)):\n",
    "    initial_mistral_inputs = create_mistral_total_prompt(promptTracker.mistral_system_prompts[-1], promptTracker.target_input[i])\n",
    "    output_from_mistral = local_llm_call(initial_mistral_inputs)\n",
    "    promptTracker.mistral_responses[-1].append(output_from_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI GPT4 for refinement of system prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_sys_prompt = \"\"\"You are an AI assistant who is expert in creating promtps for LLMs. you job is to modify and enhance a prompt for a 7b mistral instruct model. The mistral model is supposed to receive an input text, and return a list of strings, entities, brand names, etc in that input text. This LLM is going to be used for .... The prompt to the mistral model can include some examples that lead the model's behavior. Mistral model performs constrained decoding, meaning that it only generates a list of strings.\n",
    "\n",
    "A number of experiments have been done on different system prompts for mistral and the output. Those experiments which include tested system prompt, tested INPUTs TO MISTRAL, and the resulting outputs from Mistral are provided to you. Your job is to observe the experiments, and come up with a better system prompt for Mistral to achieve the expected output. you can provide some examples, or remove some examples in your suggested system prompt. Remember that total number of examples should be limited to 3, because it adds extra computation and we can't afford it. Note that the examples given in the system prompt of mistral should be enclosed by ### ###. Pay attention to the fact that, you are NOT allowed to use EVALUATION INPUT TO MISTRAL texts in your examples for your suggested mistral system prompt.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Gun violence', 'Coca-cola', 'Kansas city']\", \"['Paris', 'Honeymoon']\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTracker.target_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openai_user_prompt(prompttracker):\n",
    "    total_prompt = \"\"\n",
    "\n",
    "    for i in range(len(prompttracker.mistral_responses)):\n",
    "        total_prompt += f\"\"\"\\n\\n\\n\\n\n",
    "Experiment {i}\n",
    "Mistral System Prompt:\n",
    "{prompttracker.mistral_system_prompts[i]}\n",
    "\"\"\"\n",
    "        for j in range(len(prompttracker.target_input)):\n",
    "            total_prompt += f\"\"\"\\n\\n\n",
    "\n",
    "EVALUATION INPUT {j} TO MISTRAL:\n",
    "{prompttracker.target_input[j]}\n",
    "EVALUATION OUTPUT {j} FROM MISTRAL:\n",
    "{prompttracker.mistral_responses[i][j]}\n",
    "what was EXPECTED to be EVALUATION OUTPUT {j} from MISTRAL:\n",
    "{str(prompttracker.target_output[j])} \\n\\n\n",
    "\"\"\"\n",
    "        \n",
    "    return total_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSystemPrompt(BaseModel):\n",
    "    #the list name has an important effect on the response! choose it wisely!\n",
    "    Enhanced_System_Prompt: str\n",
    "\n",
    "\n",
    "def request_to_openai(prompttracker):\n",
    "    openai_user_prompt = create_openai_user_prompt(prompttracker=prompttracker)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        temperature = 0.1,\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": openai_sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": openai_user_prompt},\n",
    "            ],\n",
    "        functions=[\n",
    "            {\n",
    "            \"name\": \"Enhanced_System_Prompt\",\n",
    "            \"description\": \"Enhanced System Prompt for Mistral LLM\",\n",
    "            \"parameters\": EnhancedSystemPrompt.model_json_schema()\n",
    "            }\n",
    "        ],\n",
    "        function_call={\"name\": \"Enhanced_System_Prompt\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.function_call.arguments)['Enhanced_System_Prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_system_prompt_with_gpt4(number_of_iterations):\n",
    "    for i in range(number_of_iterations):\n",
    "        openai_suggestion = request_to_openai(prompttracker=promptTracker)\n",
    "        promptTracker.mistral_system_prompts.append(openai_suggestion)\n",
    "        promptTracker.mistral_responses.append([])\n",
    "        for j in range(len(promptTracker.target_input)):\n",
    "            mistral_inputs = create_mistral_total_prompt(promptTracker.mistral_system_prompts[-1], promptTracker.target_input[j])\n",
    "            output_from_mistral = local_llm_call(mistral_inputs)\n",
    "            promptTracker.mistral_responses[-1].append(output_from_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_system_prompt_with_gpt4(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['Gun violence', 'Coca-cola', 'Kansas city']\", \"['Paris', 'Honeymoon']\"]\n"
     ]
    }
   ],
   "source": [
    "print(promptTracker.target_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['Gun violence', 'Celebration', 'Joy', 'America', 'Kansas']\", \"['Honeymoon', 'Paris', 'Travel']\"]\n",
      "[\"['Kansas', 'America', 'Gun violence']\", \"['Paris', 'Honeymoon']\"]\n",
      "[\"['Kansas', 'America', 'Gun violence', 'Coca-Cola']\", \"['Paris', 'Honeymoon']\"]\n",
      "[\"['Kansas', 'America', 'Gun violence', 'Coca-Cola']\", \"['Paris']\"]\n",
      "[\"['Kansas', 'America', 'Gun violence', 'Coca-Cola']\", \"['Paris']\"]\n",
      "[\"['America', 'Gun violence', 'Kansas', 'Coca-Cola']\", \"['Paris']\"]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(promptTracker.mistral_responses)):\n",
    "    print(promptTracker.mistral_responses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI designed to extract a concise list of specific entities, brand names, or unique concepts from a given piece of text. The list should not exceed 10 items and must focus on the most distinctive elements mentioned, prioritizing locations, notable brands, and any specific details directly referenced in the text. Use standardized words for entities and concepts, and ensure to capture specific locations (e.g., 'Kansas City' instead of 'Kansas') and brand names as mentioned in the text. Avoid general terms unless they are central to the text's meaning. Emphasize capturing events or occasions if they are a focal point of the text. Additionally, when a sentiment or event is mentioned, identify and list it if it significantly impacts the context of the text.\n",
      "\n",
      "###\n",
      "Text: \"The new iPhone 12 was released yesterday, sparking interest among tech enthusiasts and Apple fans alike.\"\n",
      "Concepts_List: [\"iPhone 12\", \"Tech enthusiasts\", \"Apple\"]\n",
      "###\n",
      "\n",
      "###\n",
      "Text: \"A devastating earthquake hit the San Francisco area, causing widespread damage and concern among residents.\"\n",
      "Concepts_List: [\"Earthquake\", \"San Francisco\", \"Damage\"]\n",
      "###\n",
      "\n",
      "###\n",
      "Text: \"Global warming is leading to increased temperatures worldwide, affecting wildlife and raising concerns about climate change.\"\n",
      "Concepts_List: [\"Global warming\", \"Wildlife\", \"Climate change\"]\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(promptTracker.mistral_system_prompts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
